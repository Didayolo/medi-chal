{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing data distributions\n",
    "\n",
    "** We want to compare the different representations and meta-features of two distributions to characterize their similarities and differences (e.g. original data VS generated data). **\n",
    "\n",
    "- Data format : autoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../data'\n",
    "\n",
    "datasets = {'iris': (data_dir + '/iris', 'iris'),\n",
    "            'iris_1': (data_dir + '/iris_1', 'iris'),\n",
    "            'iris_2': (data_dir + '/iris_2', 'iris'),\n",
    "            'mimic': (data_dir + '/mimic', 'mimic'),\n",
    "            'mimic_artif': (data_dir + '/mimic', 'mimic_artif'),\n",
    "            'mushrooms': (data_dir + '/mushrooms', 'mushrooms'),\n",
    "            'chems': (data_dir + '/chems', 'chems'),\n",
    "            'credit': (data_dir + '/credit_data', 'credit'),\n",
    "            'squares': (data_dir + '/squares', 'squares'),\n",
    "            'squares_2': (data_dir + '/squares_2', 'squares')}\n",
    "\n",
    "# First dataset.\n",
    "input_dir1, basename1 = datasets['iris_1']\n",
    "#input_dir1, basename1 = datasets['mimic']\n",
    "\n",
    "# Second dataset.\n",
    "input_dir2, basename2 = datasets['iris_2']\n",
    "#input_dir2, basename2 = datasets['mimic_artif']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison\n",
    "\n",
    "- ** Overall meta-features ** (descriptors): we compute simple distances between the descriptors of each dataset.\n",
    "- ** Individual features/variables ** (column comparison):\n",
    "\n",
    "    - Numerical:\n",
    "        - Kolmogorov-Smirnov test\n",
    "        \n",
    "    - Categorical, binary:\n",
    "        - Mutual information score: This is equal to the Kullback-Leibler divergence of the joint distribution with the product distribution of the marginals\n",
    "        - Kullback-Leibler divergence\n",
    "        - Jensen-Shannon divergence\n",
    "\n",
    "- ** Discriminant ** (row comparison): we label the data with 0 or 1 according to their original dataset and then train a binary classifier on it. This is the method used to train GANs. More sophisticated the classifier which succeeds in separating the data is, more similar they are. If the classifier can't separate the data, maybe they are to similar, maybe the classifier isn't good enough. \n",
    "- ** Landmark: ** performance in prediction of the target among various models and metrics.\n",
    "- ** Change of representations: ** we train an auto-encoder on dataset A and benchmark it on dataset B (and reciprocally). The intuition behind this is that similar data will be compressible in the same latent space. This principle could be applied to other changes of representation.\n",
    "- ** Causal inference: ** comparison of causal inference results. Do we notice the same causal links between the variables?\n",
    "\n",
    "Draft:\n",
    "- Wasserstein distance (minimum cost of turning one \"pile of dirt\" into the other)\n",
    "- Chi square\n",
    "- Metrics of **privacy** and **resemblance** between two datasets:\n",
    "    - Area under MDA curve with threshold\n",
    "    - MMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoML\n",
    "import sys\n",
    "main_path = '../../'\n",
    "sys.path.append(main_path + 'code/auto_ml')\n",
    "sys.path.append(main_path + 'code/processing')\n",
    "sys.path.append(main_path + 'code/functions')\n",
    "sys.path.append(main_path + 'code/models')\n",
    "sys.path.append(main_path + 'data')\n",
    "\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = AutoML(input_dir1, basename1)\n",
    "ds2 = AutoML(input_dir2, basename2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Numerical', 'Numerical', 'Numerical', 'Numerical']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds1.feat_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auto_ml import AutoML\n",
    "from comparator import Comparator\n",
    "\n",
    "comparator = Comparator(AutoML(input_dir1, basename1), AutoML(input_dir2, basename2))\n",
    "#df1 = AutoML.from_csv(input_dir1, basename1, 'final_df_sdv.csv')\n",
    "#df2 = AutoML.from_csv(input_dir2, basename2, 'artificial_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparator = Comparator(df1, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance between descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing proba: 0.0\n",
      "Ratio: 0.0\n",
      "Skewness max: 0.36138783439073113\n",
      "Skewness mean: 0.3892252331784053\n",
      "Symb ratio: 0.0\n",
      "Skewness min: 0.4821269415958557\n",
      "Class deviation: 0.04124611185697713\n"
     ]
    }
   ],
   "source": [
    "#comparator.compare_descriptors(norm='euclidean')\n",
    "comparator.show_descriptors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual features comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Kolmogorov-Smirnov</th>\n",
       "      <td>(0.16667, 0.76005)</td>\n",
       "      <td>(0.2, 0.5372)</td>\n",
       "      <td>(0.16667, 0.76005)</td>\n",
       "      <td>(0.16667, 0.76005)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          sepal_length    sepal_width        petal_length  \\\n",
       "Kolmogorov-Smirnov  (0.16667, 0.76005)  (0.2, 0.5372)  (0.16667, 0.76005)   \n",
       "\n",
       "                           petal_width  \n",
       "Kolmogorov-Smirnov  (0.16667, 0.76005)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comparator.show_comparison_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary classification scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "** Score: **0.7"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "** Score: **0.7"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comparator.show_classifier_score()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "comparator.show_classifier_score(clf=RandomForestClassifier(n_estimators=200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Privacy/Resemblance metric\n",
    "- ** MDA: ** Minimum Distance Accumulation\n",
    "- Privacy: Area above curve on the left of the threshold\n",
    "- Resemblance: Area under curve on the right of the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparator.compute_mda(norm='manhattan', precision=0.1, threshold=0.4)\n",
    "comparator.show_mda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** MMD: ** Maximum Mean Discrepancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparator.show_mmd()\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only if same number of samples !\n",
    "#comparator.dcov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only if same number of samples !\n",
    "# Norm = 'l0',\n",
    "#        'manhattan' or 'l1', \n",
    "#        'euclidean' or 'l2',\n",
    "#        'minimum',\n",
    "#        'maximum',\n",
    "#comparator.datasets_distance(axis=0, norm='manhattan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
