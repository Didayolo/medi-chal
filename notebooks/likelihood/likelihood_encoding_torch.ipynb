{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood encoding benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "main_path = '../../'\n",
    "sys.path.append(main_path + 'code/auto_ml')\n",
    "sys.path.append(main_path + 'code/processing')\n",
    "sys.path.append(main_path + 'code/models')\n",
    "sys.path.append(main_path + 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(main_path + 'data/mimic/final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['DIED'], axis=1)\n",
    "y = pd.DataFrame(data['DIED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization available = standard.\n",
    "normalization = ['standard']\n",
    "# Encoding available = label, one-hot, likelihood.\n",
    "encoding = ['none', 'label', 'one-hot', 'likelihood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processing import processing\n",
    "\n",
    "def process_and_split(X, y, normalization, encoding):\n",
    "    print('Processing with', nrm, 'normalization and', ecd, 'encoding...')\n",
    "    X_preprocessed = processing(X, normalization, encoding).values\n",
    "    y_preprocessed = processing(y, 'none', 'label').values.reshape(-1, 1)\n",
    "    \n",
    "    print('X shape: ', X_preprocessed.shape)\n",
    "    print('y shape: ', y_preprocessed.shape)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y_preprocessed, train_size=0.7, test_size=0.3)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing with standard normalization and none encoding...\n",
      "X shape:  (26927, 1062)\n",
      "y shape:  (26927, 1)\n",
      "Training model...\n",
      "Model trained in  1.310999870300293 s.\n",
      "Train accuracy:  0.9394100169779287\n",
      "Test accuracy:  0.9249907166728556\n",
      "\n",
      "\n",
      "Processing with standard normalization and label encoding...\n",
      "X shape:  (26927, 1068)\n",
      "y shape:  (26927, 1)\n",
      "Training model...\n",
      "Model trained in  1.8622801303863525 s.\n",
      "Train accuracy:  0.9386672325976231\n",
      "Test accuracy:  0.9308082683500434\n",
      "\n",
      "\n",
      "Processing with standard normalization and one-hot encoding...\n",
      "X shape:  (26927, 1211)\n",
      "y shape:  (26927, 1)\n",
      "Training model...\n",
      "Model trained in  3.0605862140655518 s.\n",
      "Train accuracy:  0.9380305602716469\n",
      "Test accuracy:  0.935388043074638\n",
      "\n",
      "\n",
      "Processing with standard normalization and likelihood encoding...\n",
      "X shape:  (26927, 1068)\n",
      "y shape:  (26927, 1)\n",
      "Training model...\n",
      "Model trained in  2.0661611557006836 s.\n",
      "Train accuracy:  0.9391447368421053\n",
      "Test accuracy:  0.9285802698353757\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import product\n",
    "import time\n",
    "\n",
    "for nrm, ecd in product(normalization, encoding):\n",
    "    X_train, X_test, y_train, y_test = process_and_split(X, y, nrm, ecd)\n",
    "    y_train, y_test = np.ravel(y_train), np.ravel(y_test)\n",
    "    \n",
    "    reg = LogisticRegression()\n",
    "    \n",
    "    print('Training model...')\n",
    "\n",
    "    t1 = time.time()\n",
    "    reg.fit(X_train, y_train)\n",
    "    t2 = time.time()\n",
    "    \n",
    "    print('Model trained in ', t2-t1, 's.')\n",
    "\n",
    "    print('Train accuracy: ', accuracy_score(np.round(reg.predict(X_train)), y_train))\n",
    "    print('Test accuracy: ', accuracy_score(np.round(reg.predict(X_test)), y_test))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing with standard normalization and none encoding...\n",
      "X shape:  (26927, 1062)\n",
      "y shape:  (26927, 1)\n",
      "Training model...\n",
      "Training finished in 13.099853038787842 s. \n",
      "\n",
      "Processing with standard normalization and label encoding...\n",
      "X shape:  (26927, 1068)\n",
      "y shape:  (26927, 1)\n",
      "Training model...\n",
      "Training finished in 11.800348997116089 s. \n",
      "\n",
      "Processing with standard normalization and one-hot encoding...\n",
      "X shape:  (26927, 1211)\n",
      "y shape:  (26927, 1)\n",
      "Training model...\n",
      "Training finished in 12.66047215461731 s. \n",
      "\n",
      "Processing with standard normalization and likelihood encoding...\n",
      "X shape:  (26927, 1068)\n",
      "y shape:  (26927, 1)\n",
      "Training model...\n",
      "Training finished in 10.98168683052063 s. \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import run_model_torch\n",
    "import time\n",
    "from itertools import product\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "fig1, ax1 = plt.subplots(1, 1, figsize=(12, 8))\n",
    "fig2, ax2 = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n",
    "\n",
    "for nrm, ecd in product(normalization, encoding):\n",
    "    X_train, X_test, y_train, y_test = process_and_split(X, y, nrm, ecd)\n",
    "    \n",
    "    print('Training model...')\n",
    "    \n",
    "    t1 = time.time()\n",
    "    losses, train_acc, test_acc = run_model_torch.training(X_train, y_train, X_test, y_test)\n",
    "    t2 = time.time()\n",
    "    \n",
    "    print('Training finished in', t2-t1, 's. \\n')\n",
    "    \n",
    "    ax1.plot(losses, 'o-', label=nrm + ' ' +  ecd)\n",
    "    ax2[0].plot(train_acc, 'o-', label=nrm + ' ' +  ecd)\n",
    "    ax2[1].plot(test_acc, 'o-', label=nrm + ' ' +  ecd)\n",
    "    \n",
    "ax1.legend()\n",
    "ax1.set_title('Loss')\n",
    "ax2[0].legend()\n",
    "ax2[0].set_title('Training Accuracy')\n",
    "ax2[1].legend()\n",
    "ax2[1].set_title('Testing Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
